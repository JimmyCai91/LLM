# LLM

- Multi-Query Attention (MQA): https://blog.fireworks.ai/multi-query-attention-is-all-you-need-db072e758055
